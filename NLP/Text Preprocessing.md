- Remove stop words
- [[Tokenization]]
	- Separating a piece of text into smaller units, most common example is WhiteSpaceTokenizer
	- Used to obtain vocabulary
- Stemming
	- cutting off end or beginning of the word, taking into account a list of common prefixes and suffixes
- Lemmatization
	- Takes into consideration the morphological analysis of the words. Usually have a dictionary to look through a word back to its lemma