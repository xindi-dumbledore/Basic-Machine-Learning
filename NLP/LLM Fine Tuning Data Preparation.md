#LLM #finetuning

- Raw text - used for continuous pre-training
- [[Fine-tuning LLMs with instruction]]
- Chat Fine-tuning - data is a multi0turn conversation between Human and Assistant

### Guidlines
- Chat or instruction tuning is better than raw corpus
- Use chat/instruction fine-tuning even it's a single task
- Pay attention to model's context length!