## Clarifying Requirements
- Business Objective: increase user experience by serving them similar images of their choice, increase click-through-rate
- Is the system cold-start or we already have a certain application, but want to improve on it?
- Do we have human-labeled data, or we are going to use user interaction data to build the model?
- What is the scale of the system? How many images, how many users, how many requests per minute
- Is it personalized?
- How many similar images we are going to serve per request?
- How fast would it need? Do we prioritize accuracy over latency?
## Frame it as an ML task
- ML objective: retrieve images with high similarity
- I/O
	- Input: user selected image
	- Output: a list of similar images ranked from most similar to least similar
- ML category
	- We need to find similar images, to do that, we can map each image to an embedding, so that we can find image with similar embeddings. Then we can rank the images by similarity scores.
	- Key is to map image to embedding space -> representation learning
## Data
### What
- Since we are not offering personalized experience for users, we don't really need user features.
- We need information about image
	- image id, image file, upload time, tags
- We need user interaction data of the current system, so we can create labeled data
	- user request image id, similar image id, position in the list, interaction (impression or click), time stamp
### Preparation
- Image processing: we need to process the image so that they are of the same size, and scale the pixels, make sure they are all in the same color schema etc.
- Create dataset: our dataset can look something like this
![[Screenshot 2025-03-31 at 13.27.30.png]]
- Data augmentation: we can also augment the data to create positive examples, such as rotating the original image, crop etc. Using augmented image as the positive example is called self-supervised learning, and is found to be effective in frameworks like SimCLR and MoCo.
### Model details
Our model can look something like this:
1. We have an embedding model that will convert each image into an embedding
2. After getting the embedding of all the images of one dataset, we can use contrastive loss to update the embedding model
![[Screenshot 2025-03-31 at 13.36.45.png]]
### Embedding model structure
Since we are working with images, we can choose CNN framework for the embedding model. We can also us pre-trained image embedding model to speed up the training.
## Evaluation

### Offline Evaluation
Our evaluation dataset looks similar as the dataset we used for training, but we know the similarity score or ranking for the image pool.
We will then send all these images to our embedding model and get their embeddings, then calculate the similarity between them and the anchor image![[Screenshot 2025-03-31 at 13.56.10.png]]
As we can see, it is a ranking problem, so we can use common ranking metrics for the evaluation, see [[Learning to Rank Evaluation Measures]]
### Online Evaluation
The most direct online evaluation metric we can use is click-through rate (CTR), which is calculated as: CTR = (Number of Clicked images)/(Total number of suggested images).
We can also use average daily, weekly, and monthly time spent on the suggested images to see how engaged users are with the suggested images.
## Serving
In serving, we need to return a ranked list of similar images based on the anchor image. To do that, we need several components:
1. Embedding generation
2. Index the images
3. Retrieve nearest neighbors of the given anchor image
4. Re-ranking
![[Screenshot 2025-03-31 at 14.11.12.png]]
- With new images coming in, we would get their embeddings and add them to the index table
- When a anchor image is selected, we would get the embedding from the index table, then use the nearest neighbor service to get the nearest neighbors, i.e. most similar images. There are a lot of choices for the nearest neighbor algorithms, for details, see [[Nearest Neighbor Search Algorithms]]
- The final reranking step can take into things like sponsor images, filter inappropriate results, removes duplicates etc.