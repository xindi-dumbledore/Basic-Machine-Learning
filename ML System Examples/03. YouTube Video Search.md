## Description
User enters text into the search box, and the system displays the most relevant videos for the given text.
## Clarifying Requirements
- Is the query text only?
- What information of the video we can use? Video itself, some meta data (tags, title, description, popularity etc.)
- What kind of data is available? <video, text query>
- How many videos are there on the platform? One billion videos
- Do we need to personalized results for users? No

## Frame it as an ML task
- ML objective: retrieve videos that are most relevant to the text query, rank them from most relevant to least relevant.
- I/O: input - user query, output - list of videos ranked from most relevant to least relevant
- ML category
	- Since we are using both the video content and the video metadata, we can have two search system: visual search and text search, then fuse them together to generate the final result
	- Visual search: use to encoders to transfer query and video into embeddings, then we can calculate the similarity between the embeddings ![[Screenshot 2025-04-01 at 13.15.29.png]]
	- Text search: We can use inverted index techniques for text search. A popular choice is to use Elastic Search