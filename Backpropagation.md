## One Line Summary
Backpropagation is a method to calculate gradients in the neural network utilizing the chain rule. It reuse derivatives computed for higher layers in computing derivatives for lower layers to minimize computation.

## Detail
![[backprop1.png]]
![[backprop2.png]]